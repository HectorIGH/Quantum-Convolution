{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Initial Conv2D Layers is replaced for a custom build Qonv2D\n",
    "which implements a trainable quantum circuit. The Qonv2D is set\n",
    "for a kernel_size = (2, 2), but the strides can be varied. Since it has\n",
    "padding implementation only computes 'valids' convolution, nevertheless is\n",
    "really straightforward to implement the padding which enables 'same' convolutions.\n",
    "\n",
    "\n",
    "\n",
    "Too much computationally complex for now. Takes a lot to train\n",
    "and the model performance slowly increase at each epoch.\n",
    "Presumably with more time the model can achieve good performance,\n",
    "nevertheless I am yet to be able to let the model run for a very long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T02:13:48.112163Z",
     "start_time": "2020-12-25T02:13:48.098221Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from qiskit import ClassicalRegister, QuantumRegister, QuantumCircuit, Aer, execute, IBMQ\n",
    "from qiskit.tools.visualization import circuit_drawer\n",
    "from qiskit.tools.visualization import plot_histogram\n",
    "from qiskit.extensions.unitary import unitary\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "from qiskit.compiler import transpile, assemble\n",
    "from qiskit.providers.aer import QasmSimulator\n",
    "S_simulator = Aer.backends(name = 'statevector_simulator')[0]\n",
    "M_simulator = Aer.backends(name = 'qasm_simulator')[0]\n",
    "\n",
    "backend = QasmSimulator(configuration = {'method' : 'density_matrix'})\n",
    "M_simulator = backend\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy import misc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Quantum Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T02:13:48.812256Z",
     "start_time": "2020-12-25T02:13:48.801311Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convolution(FOCUS_TENSOR, FILTER, shots = 8192):\n",
    "    '''\n",
    "    FOCUS = [[F00, F01],\n",
    "             [F10, F11]]\n",
    "    FILTER = [[FI00, FI01],\n",
    "              [FI10, FI11]]\n",
    "    '''\n",
    "    q = QuantumRegister(4, name = 'q_r')\n",
    "    a = QuantumRegister(1, name = 'a_r')\n",
    "    c = ClassicalRegister(1, name = 'c_r')\n",
    "    qc = QuantumCircuit(q, a, c, name = 'q_circ')\n",
    "    \n",
    "    FOCUS = FOCUS_TENSOR.numpy()\n",
    "\n",
    "    qc.h(q)\n",
    "\n",
    "    qc.u3(FOCUS[0, 0] * FILTER[0, 0], FOCUS[0, 0] * FILTER[0, 1], FOCUS[0, 0] * FILTER[1, 0], q[0])\n",
    "\n",
    "    qc.u3(FOCUS[0, 1] * FILTER[0, 0], FOCUS[0, 1] * FILTER[0, 1], FOCUS[0, 1] * FILTER[1, 0], q[1])\n",
    "\n",
    "    qc.u3(FOCUS[1, 0] * FILTER[0, 0], FOCUS[1, 0] * FILTER[0, 1], FOCUS[1, 0] * FILTER[1, 0], q[2])\n",
    "\n",
    "    qc.u3(FOCUS[1, 1] * FILTER[0, 0], FOCUS[1, 1] * FILTER[0, 1], FOCUS[1, 1] * FILTER[1, 0], q[3])\n",
    "    \n",
    "    qc.h(q)\n",
    "\n",
    "    qc.mct(q, a, None, mode = 'noancilla')\n",
    "\n",
    "    qc.measure(a[0], c)\n",
    "\n",
    "    #transpiled_circuit = transpile(qc, M_simulator, optimization_level = 1)\n",
    "    #job = M_simulator.run(assemble(transpiled_circuit, shots = shots))\n",
    "    job = execute(qc, M_simulator, shots = shots, optimization_level = 1)\n",
    "    results = job.result()\n",
    "\n",
    "    readout = results.get_counts()\n",
    "    convolution = (readout.get('1', 0) / shots) * FILTER[1, 1]\n",
    "    return convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T02:16:19.906190Z",
     "start_time": "2020-12-25T02:16:19.899207Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def qonv2D(FILTERS = None, kernel_size = (2, 2), stride = (1, 1), image = None):\n",
    "    KERNEL = kernel_size\n",
    "    STRIDE = stride\n",
    "    N_FILTERS = FILTERS.shape[0]\n",
    "    CONV_SHAPE = ((image.shape[0] - KERNEL[0]) // STRIDE[0] + 1, (image.shape[0] - KERNEL[0]) // STRIDE[1] + 1, N_FILTERS)\n",
    "    #tf.print(image.numpy().shape)\n",
    "    \n",
    "    #CONV_IMAGE = [[] for _ in range(N_FILTERS)]\n",
    "    CONV_IMAGE = np.zeros(shape = CONV_SHAPE)\n",
    "    #tf.print(CONV_IMAGE.shape)\n",
    "    for row in range(0, image.shape[0] - KERNEL[0] + 1, STRIDE[0]):\n",
    "        for col in range(0, image.shape[1] - KERNEL[1] + 1, STRIDE[1]):\n",
    "            for index, FILTER in enumerate(FILTERS):\n",
    "                focus = image[row : row + KERNEL[0], col : col + KERNEL[1]]\n",
    "                convol = convolution(focus, FILTER, shots = 100)\n",
    "                #CONV_IMAGE[index].append(convol)\n",
    "                CONV_IMAGE[row // STRIDE[0], col // STRIDE[1], index] = convol\n",
    "    #CONV_OUTPUT = np.stack(CONV_IMAGE, axis = -1)\n",
    "    #CONV_OUTPUT = CONV_OUTPUT.reshape(CONV_SHAPE)\n",
    "    #tf.print(CONV_IMAGE.shape)\n",
    "    return CONV_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Custom Keras Layer implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T01:55:11.444205Z",
     "start_time": "2020-12-25T01:55:11.434232Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Qonv2D(layers.Layer):\n",
    "    def __init__(self, filters = 1, kernel_size = (2, 2), strides = (1, 1), input_shape = (28, 28)):\n",
    "        super(Qonv2D, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.f = self.add_weight(\n",
    "            name = \"filters_customized\",\n",
    "            shape = (self.filters, self.kernel_size[0], self.kernel_size[1]),\n",
    "            initializer = \"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Qonv2D, self). get_config()\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Exotic calculations\n",
    "        if tf.executing_eagerly():\n",
    "            final_output = []\n",
    "            #tf.print(f'Inputs shape: {inputs.shape}')\n",
    "            for i in range(inputs.shape[0]): # For volume in batch\n",
    "                # Dummy operation\n",
    "                pred = qonv2D(FILTERS = self.f.numpy(), kernel_size = self.kernel_size, stride = self.strides, image = inputs[i])\n",
    "                final_output.append(list(pred))\n",
    "                    \n",
    "            #final_output = np.vstack((final_output))\n",
    "            ans = tf.convert_to_tensor(final_output, dtype = \"float32\")\n",
    "            return ans\n",
    "        return Conv2D(self.filters, kernel_size = self.kernel_size, strides = self.strides)(inputs)\n",
    "    \n",
    "class MyReLu(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyReLu, self).__init__()\n",
    "    def call(self, x):\n",
    "        return tf.math.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T01:55:11.455175Z",
     "start_time": "2020-12-25T01:55:11.445202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def MyModel(width, height, depth, classes):\n",
    "    input_shape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Qonv2D(filters = 4, kernel_size = (2, 2), strides = (2, 2), input_shape = (width, height, depth)))\n",
    "    model.add(Activation(tf.nn.relu))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3, 3)))\n",
    "    model.add(Activation(tf.nn.relu))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\"))\n",
    "    model.add(Activation(tf.nn.relu))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(units = 10))\n",
    "    #model.add(Activation(tf.nn.relu))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(units = classes))\n",
    "    model.add(Activation(tf.nn.softmax))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T01:55:11.920983Z",
     "start_time": "2020-12-25T01:55:11.456172Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialize epochs, batch size and initial learning rate\n",
    "EPOCHS = 1\n",
    "BS = 1\n",
    "INIT_LR = 0.001\n",
    "\n",
    "# Loading MNIST\n",
    "((X_train, Y_train), (X_test, Y_test)) = mnist.load_data()\n",
    "\n",
    "# Adding a channel dimension and scaling\n",
    "X_train = np.expand_dims(X_train, axis = -1)\n",
    "X_test = np.expand_dims(X_test, axis = -1)\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# One-hot encoding\n",
    "Y_train = to_categorical(Y_train, 10)\n",
    "Y_test = to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T01:55:11.926912Z",
     "start_time": "2020-12-25T01:55:11.921960Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "opt = Adam(learning_rate = INIT_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T01:55:12.196230Z",
     "start_time": "2020-12-25T01:55:12.018669Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define our metrics\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy('train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy('test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T02:08:33.849237Z",
     "start_time": "2020-12-25T02:08:33.842285Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#@tf.function # Needed to make sure gradients are recorded\n",
    "def train_step(model, opt, x_train, y_train):\n",
    "    # Keep track of our gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make a prediction with the model and use it to calculate loss\n",
    "        predictions = model(x_train, training = True)\n",
    "        #tf.print(predictions)\n",
    "        loss = loss_object(y_train, predictions)\n",
    "    # Calculate the gradient using our tape and then update the model weights\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    tf.print([(v.name, v) for v in model.trainable_variables])\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y_train, predictions)\n",
    "\n",
    "def test_step(model, x_test, y_test):\n",
    "    predictions = model(x_test)\n",
    "    loss = loss_object(y_test, predictions)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T02:08:34.452648Z",
     "start_time": "2020-12-25T02:08:34.434696Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Building model and initialize optimizer\n",
    "model = MyModel(28, 28, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T02:10:49.275324Z",
     "start_time": "2020-12-25T02:10:49.266375Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "qonv2d_4 (Qonv2D)            (1, 14, 14, 4)            16        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (1, 14, 14, 4)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (1, 14, 14, 4)            16        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (1, 7, 7, 4)              0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (1, 5, 5, 32)             1184      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (1, 5, 5, 32)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (1, 5, 5, 32)             128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (1, 2, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (1, 2, 2, 64)             18496     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (1, 2, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (1, 2, 2, 64)             256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (1, 1, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (1, 64)                   0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (1, 64)                   0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, 10)                   650       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (1, 10)                   0         \n",
      "=================================================================\n",
      "Total params: 20,746\n",
      "Trainable params: 20,546\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T02:08:35.718262Z",
     "start_time": "2020-12-25T02:08:35.714248Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train = X_train[0:50]\n",
    "x_test = X_test[0:20]\n",
    "y_train = Y_train[0:50]\n",
    "y_test = Y_test[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T02:08:36.201080Z",
     "start_time": "2020-12-25T02:08:36.185158Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T02:10:34.912625Z",
     "start_time": "2020-12-25T02:08:36.738056Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compute number of bacthes updates per epoch\n",
    "numUpdatesTrain = x_train.shape[0] // BS\n",
    "numUpdatesTest = x_test.shape[0] // BS\n",
    "\n",
    "# Looping over the number of epochs\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"[INFO] starting epoch {epoch + 1}/{EPOCHS}...\", end = \"\")\n",
    "    sys.stdout.flush()\n",
    "    epochStart = time.time()\n",
    "    \n",
    "    # Looping over the data in batch size increments\n",
    "    for i in range(numUpdatesTrain):\n",
    "        # Determine starting and ending slice indexes for the current batch\n",
    "        start = i * BS\n",
    "        end = start + BS\n",
    "        \n",
    "        # Take a step\n",
    "        train_step(model, opt, x_train[start: end], y_train[start: end])\n",
    "        \n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step = epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step = epoch)\n",
    "    \n",
    "    # Looping over the data in batch size increments\n",
    "    for i in range(numUpdatesTest):\n",
    "        # Determine starting and ending slice indexes for the current batch\n",
    "        start = i * BS\n",
    "        end = start + BS\n",
    "        \n",
    "        # Take a step\n",
    "        test_step(model, x_test[start: end], y_test[start: end])\n",
    "    \n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step = epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step = epoch)\n",
    "        \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result() * 100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))\n",
    "    \n",
    "    # Reset metrics every epoch\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    # Show timing information for the epoch\n",
    "    epochEnd = time.time()\n",
    "    elapsed = (epochEnd - epochStart) / 60.0\n",
    "    print(f\"took {elapsed:.4} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T20:55:34.335728Z",
     "start_time": "2020-12-24T20:55:34.317778Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17356), started 0:03:13 ago. (Use '!kill 17356' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fc86feb58e6e24bc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fc86feb58e6e24bc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs\\gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
