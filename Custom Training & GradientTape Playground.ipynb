{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:45:18.876447Z",
     "start_time": "2020-12-24T02:45:14.697071Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:45:18.881370Z",
     "start_time": "2020-12-24T02:45:18.877382Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:46:00.914881Z",
     "start_time": "2020-12-24T02:45:58.769704Z"
    }
   },
   "outputs": [],
   "source": [
    "from qiskit import ClassicalRegister, QuantumRegister, QuantumCircuit, Aer, execute, IBMQ\n",
    "from qiskit.tools.visualization import circuit_drawer\n",
    "from qiskit.tools.visualization import plot_histogram\n",
    "from qiskit.extensions.unitary import unitary\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "from qiskit.compiler import transpile, assemble\n",
    "from qiskit.providers.aer import QasmSimulator\n",
    "S_simulator = Aer.backends(name = 'statevector_simulator')[0]\n",
    "M_simulator = Aer.backends(name = 'qasm_simulator')[0]\n",
    "\n",
    "backend = QasmSimulator(configuration = {'method' : 'density_matrix'})\n",
    "M_simulator = backend\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy import misc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:37:04.948646Z",
     "start_time": "2020-12-23T04:37:04.877822Z"
    }
   },
   "outputs": [],
   "source": [
    "'''def quanvolution(param):\n",
    "    q = QuantumRegister(4, name = 'q_r')\n",
    "    a = QuantumRegister(1, name = 'a_r')\n",
    "    c = ClassicalRegister(1, name = 'c_r')\n",
    "    qc = QuantumCircuit(q, a, c, name = 'q_circ')\n",
    "\n",
    "    qc.h(q)\n",
    "\n",
    "    qc.u3(param[0, 0], param[0, 1], param[0, 2], q[0])\n",
    "    qc.u3(param[1, 0], param[1, 1], param[1, 2], q[0])\n",
    "    qc.u3(param[2, 0], param[2, 1], param[2, 2], q[0])\n",
    "    qc.u3(param[3, 0], param[3, 1], param[3, 2], q[0])\n",
    "\n",
    "    qc.mct(q, a, None, mode = 'noancilla')\n",
    "\n",
    "    qc.measure(a[0], c)\n",
    "\n",
    "    shots = 8192\n",
    "\n",
    "    transpiled_circuit = transpile(qc, M_simulator, optimization_level = 1)\n",
    "    job = M_simulator.run(assemble(transpiled_circuit, shots = shots))\n",
    "    results = job.result()\n",
    "\n",
    "    readout = results.get_counts()\n",
    "\n",
    "    #print(readout.get('1', 0) / readout.get('0', shots))\n",
    "    \n",
    "    #qc.draw()\n",
    "    \n",
    "    return [readout.get('0', 0) / readout.get('1', shots)] * param.shape[-1]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:46:53.034311Z",
     "start_time": "2020-12-24T02:46:53.025330Z"
    }
   },
   "outputs": [],
   "source": [
    "def convolution(FOCUS, FILTER, shots = 8192):\n",
    "    '''\n",
    "    FOCUS = [[F00, F01],\n",
    "             [F10, F11]]\n",
    "    FILTER = [[FI00, FI01],\n",
    "              [FI10, FI11]]\n",
    "    '''\n",
    "    q = QuantumRegister(4, name = 'q_r')\n",
    "    a = QuantumRegister(1, name = 'a_r')\n",
    "    c = ClassicalRegister(1, name = 'c_r')\n",
    "    qc = QuantumCircuit(q, a, c, name = 'q_circ')\n",
    "\n",
    "    qc.h(q)\n",
    "\n",
    "    qc.u3(FOCUS[0, 0] * FILTER[0, 0], FOCUS[0, 0] * FILTER[0, 1], FOCUS[0, 0] * FILTER[1, 0], q[0])\n",
    "\n",
    "    qc.u3(FOCUS[0, 1] * FILTER[0, 0], FOCUS[0, 1] * FILTER[0, 1], FOCUS[0, 1] * FILTER[1, 0], q[1])\n",
    "\n",
    "    qc.u3(FOCUS[1, 0] * FILTER[0, 0], FOCUS[1, 0] * FILTER[0, 1], FOCUS[1, 0] * FILTER[1, 0], q[2])\n",
    "\n",
    "    qc.u3(FOCUS[1, 1] * FILTER[0, 0], FOCUS[1, 1] * FILTER[0, 1], FOCUS[1, 1] * FILTER[1, 0], q[3])\n",
    "    \n",
    "    qc.h(q)\n",
    "\n",
    "    qc.mct(q, a, None, mode = 'noancilla')\n",
    "\n",
    "    qc.measure(a[0], c)\n",
    "\n",
    "    #transpiled_circuit = transpile(qc, M_simulator, optimization_level = 1)\n",
    "    #job = M_simulator.run(assemble(transpiled_circuit, shots = shots))\n",
    "    job = execute(qc, M_simulator, shots = shots, optimization_level = 1)\n",
    "    results = job.result()\n",
    "\n",
    "    readout = results.get_counts()\n",
    "    convolution = (readout.get('1', 0) / shots) * FILTER[1, 1]\n",
    "    return convolution, readout, qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:53:35.146774Z",
     "start_time": "2020-12-24T02:53:35.137786Z"
    }
   },
   "outputs": [],
   "source": [
    "def Qonv2D(filters = 1, kernel_size = (2, 2), stride = (1, 1), image = None):\n",
    "    np.random.seed(465)\n",
    "    N_FILTERS = filters\n",
    "    KERNEL = kernel_size\n",
    "    STRIDE = stride\n",
    "    FILTERS = np.random.random(size = (N_FILTERS, KERNEL[0], KERNEL[1])) * np.pi\n",
    "    CONV_SHAPE = ((image.shape[0] - KERNEL[0]) // STRIDE[0] + 1, (image.shape[0] - KERNEL[0]) // STRIDE[1] + 1, N_FILTERS)\n",
    "    '''\n",
    "    CONV_SHAPE = ((image.shape[0] - KERNEL[0]) // STRIDE[0] + 1, (image.shape[0] - KERNEL[0]) // STRIDE[1] + 1)\n",
    "    CONV_OUTPUT = [] # shape = (Filters, CONV_IMAGE.shape)\n",
    "    for FILTER in FILTERS:\n",
    "        CONV_IMAGE = [] # shape = (((image.shape[0] - KERNEL[0]) // STRIDE[0] + 1, (image.shape[0] - KERNEL[0]) // STRIDE[1] + 1))\n",
    "        for row in range(0, image.shape[0] - KERNEL[0] + 1, STRIDE[0]):\n",
    "            for col in range(0, image.shape[1] - KERNEL[1] + 1, STRIDE[1]):\n",
    "                focus = image[row : row + KERNEL[0], col : col + KERNEL[1]]\n",
    "                convol = convolution(focus, FILTER, shots = 100)\n",
    "                CONV_IMAGE.append(convol[0])\n",
    "        CONV_OUTPUT.append(np.array(CONV_IMAGE).reshape(CONV_SHAPE))'''\n",
    "    CONV_IMAGE = [[] for _ in range(N_FILTERS)] # shape = (((image.shape[0] - KERNEL[0]) // STRIDE + 1, (image.shape[0] - KERNEL[0]) // STRIDE + 1))\n",
    "    for row in range(0, image.shape[0] - KERNEL[0] + 1, STRIDE[0]):\n",
    "        for col in range(0, image.shape[1] - KERNEL[1] + 1, STRIDE[1]):\n",
    "            for index, FILTER in enumerate(FILTERS):\n",
    "                focus = image[row : row + KERNEL[0], col : col + KERNEL[1]]\n",
    "                convol = convolution(focus, FILTER, shots = 100)\n",
    "                CONV_IMAGE[index].append(convol[0])\n",
    "    CONV_OUTPUT = np.stack(CONV_IMAGE, axis = -1)\n",
    "    CONV_OUTPUT = CONV_OUTPUT.reshape(CONV_SHAPE)\n",
    "    return CONV_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:47:18.923734Z",
     "start_time": "2020-12-24T02:47:18.921725Z"
    }
   },
   "outputs": [],
   "source": [
    "#quanvolution(np.random.normal(size = (4, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:49:04.730812Z",
     "start_time": "2020-12-24T02:49:04.720847Z"
    }
   },
   "outputs": [],
   "source": [
    "class Linear(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            name = \"w_customized\",\n",
    "            shape = (input_shape[-1], self.units),\n",
    "            initializer = \"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name = \"b_customized\",\n",
    "            shape = (self.units,), initializer=\"random_normal\", trainable=True,\n",
    "        )\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Linear, self). get_config()\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Exotic calculations\n",
    "        if tf.executing_eagerly():\n",
    "            final_output = []\n",
    "            for i in range(inputs.shape[0]):\n",
    "                # Dummy operation\n",
    "                #pred = quanvolution(np.random.normal(size = (4, inputs.shape[-1])))\n",
    "                pred = [0] * 2\n",
    "                final_output.append(list(pred))\n",
    "                \n",
    "            #tf.print(self.w, self.b)\n",
    "            #return  tf.matmul(tf.convert_to_tensor(final_output, dtype = tf.float32), self.w) + self.b\n",
    "            return  tf.matmul(inputs, self.w) + self.b\n",
    "            #return tf.convert_to_tensor(final_output, dtype = \"float32\")\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "class MyReLu(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyReLu, self).__init__()\n",
    "    def call(self, x):\n",
    "        return tf.math.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:49:05.232741Z",
     "start_time": "2020-12-24T02:49:05.216784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 0.09874764 -0.10956707 -0.09820347  0.1926188 ]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones((1, 4))\n",
    "linear_layer = Linear(4)\n",
    "y = linear_layer(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:57:05.978652Z",
     "start_time": "2020-12-24T02:56:33.752Z"
    }
   },
   "outputs": [],
   "source": [
    "def MyModel(width, height, depth, classes):\n",
    "    input_shape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding = \"valid\", input_shape = input_shape))\n",
    "    model.add(Activation(tf.nn.relu))\n",
    "    #model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"valid\"))\n",
    "    model.add(Activation(tf.nn.relu))\n",
    "    #model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    \n",
    "    '''model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\"))\n",
    "    model.add(Activation(tf.nn.relu))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))'''\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 10)) #### Custom Layer with gradient being recorded :D\n",
    "    model.add(Activation(tf.nn.relu))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(units = classes))\n",
    "    model.add(Activation(tf.nn.softmax))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:57:05.979650Z",
     "start_time": "2020-12-24T02:56:34.854Z"
    }
   },
   "outputs": [],
   "source": [
    "#@tf.function # Needed to make sure gradients are recorded\n",
    "def step(X, y):\n",
    "    # Keep track of our gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make a prediction with the model and use it to calculate loss\n",
    "        pred = model(X)\n",
    "        loss = categorical_crossentropy(y, pred)\n",
    "    # Calculate the gradient using our tape and then update the model weights\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    #tf.print([v.name for v in model.trainable_variables])\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:57:05.980648Z",
     "start_time": "2020-12-24T02:56:35.783Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize epochs, batch size and initial learning rate\n",
    "EPOCHS = 2\n",
    "BS = 128\n",
    "INIT_LR = 0.001\n",
    "\n",
    "# Loading MNIST\n",
    "((x_train, y_train), (x_test, y_test)) = mnist.load_data()\n",
    "\n",
    "# Adding a channel dimension and scaling\n",
    "x_train = np.expand_dims(x_train, axis = -1)\n",
    "x_test = np.expand_dims(x_test, axis = -1)\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:57:05.981645Z",
     "start_time": "2020-12-24T02:56:36.191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Building model and initialize optimizer\n",
    "model = MyModel(28, 28, 1, 10)\n",
    "opt = Adam(learning_rate = INIT_LR, decay = INIT_LR / EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:57:05.982642Z",
     "start_time": "2020-12-24T02:56:36.894Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:57:05.983640Z",
     "start_time": "2020-12-24T02:56:38.695Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute number of bacthes updates per epoch\n",
    "numUpdates = x_train.shape[0] // BS\n",
    "\n",
    "# Looping over the number of epochs\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"[INFO] starting epoch {epoch + 1}/{EPOCHS}...\", end = \"\")\n",
    "    sys.stdout.flush()\n",
    "    epochStart = time.time()\n",
    "    \n",
    "    # Looping over the data in batch size increments\n",
    "    for i in range(numUpdates):\n",
    "        # Determine starting and ending slice indexes for the current batch\n",
    "        start = i * BS\n",
    "        end = start + BS\n",
    "        \n",
    "        # Take a step\n",
    "        step(x_train[start: end], y_train[start: end])\n",
    "    \n",
    "    # Show timing information for the epoch\n",
    "    epochEnd = time.time()\n",
    "    elapsed = (epochEnd - epochStart) / 60.0\n",
    "    print(f\"took {elapsed:.4} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:57:05.983640Z",
     "start_time": "2020-12-24T02:56:39.656Z"
    }
   },
   "outputs": [],
   "source": [
    "# In order to calculate accuracy using Keras' functions we first need to compile the model\n",
    "model.compile(optimizer = opt, loss = categorical_crossentropy, metrics = [\"acc\"])\n",
    "\n",
    "# Now that the model is compiled we can compute the accuracy\n",
    "(loss, acc) = model.evaluate(x_test, y_test)\n",
    "print(f\"[INFO] test accuracy: {acc:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:57:05.984638Z",
     "start_time": "2020-12-24T02:56:41.207Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size = BS, epochs = EPOCHS * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:57:05.985647Z",
     "start_time": "2020-12-24T02:56:47.173Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:57:05.986632Z",
     "start_time": "2020-12-24T02:56:47.590Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
